{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import json\n",
    "# file_path = r'C:\\Users\\USER\\Desktop\\DSDE_project\\Project\\2018\\201800002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range()\n",
    "\n",
    "\n",
    "# # Load JSON data\n",
    "\n",
    "\n",
    "def print_nested_json(file_path_x):\n",
    "    with open(file_path_x, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    abstracts_data = data['abstracts-retrieval-response']\n",
    "    print(\"Title:\",abstracts_data['coredata']['dc:title'])\n",
    "\n",
    "    print(\"Publisher:\",abstracts_data['coredata']['dc:publisher'])\n",
    "\n",
    "    print(\"Publish date:\",abstracts_data['coredata']['prism:coverDate'])\n",
    "  \n",
    "    indexed_names = [author['preferred-name']['ce:indexed-name'] for author in abstracts_data['authors']['author']]\n",
    "    print(\"Authors:\", \", \".join(indexed_names))\n",
    "    key = [key['$'] for key in abstracts_data['authkeywords']['author-keyword']]\n",
    "    print(\"keyword:\",\", \".join(key))\n",
    "    subjects = [subject['@code'] for subject in abstracts_data['subject-areas']['subject-area']]\n",
    "    print(\"Subject:\",\", \".join(subjects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 files...\n",
      "Processed 100 files...\n",
      "Processed 200 files...\n",
      "Processed 300 files...\n",
      "Processed 400 files...\n",
      "Processed 500 files...\n",
      "Processed 600 files...\n",
      "Processed 700 files...\n",
      "Processed 800 files...\n",
      "Processed 900 files...\n",
      "Processed 1000 files...\n",
      "Processed 1100 files...\n",
      "Processed 1200 files...\n",
      "Processed 1300 files...\n",
      "Processed 1400 files...\n",
      "Processed 1500 files...\n",
      "Processed 1600 files...\n",
      "Processed 1700 files...\n",
      "Processed 1800 files...\n",
      "Processed 1900 files...\n",
      "Processed 2000 files...\n",
      "Processed 2100 files...\n",
      "Processed 2200 files...\n",
      "Processed 2300 files...\n",
      "Processed 2400 files...\n",
      "Processed 2500 files...\n",
      "Processed 2600 files...\n",
      "Processed 2700 files...\n"
     ]
    }
   ],
   "source": [
    "def process_json_to_df(file_path):\n",
    "    try:\n",
    "        # Read JSON file\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        abstracts_data = data.get('abstracts-retrieval-response', {})\n",
    "        coredata = abstracts_data.get('coredata', {})\n",
    "        \n",
    "        # Helper function to safely get joined values\n",
    "        def safe_join(data_dict, key_path, subkey=None):\n",
    "            try:\n",
    "                if not data_dict.get(key_path):\n",
    "                    return None\n",
    "                if subkey:\n",
    "                    return \", \".join([item.get(subkey, '') for item in data_dict[key_path]]) or None\n",
    "                return \", \".join(data_dict[key_path]) or None\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "        # Helper function to safely get author names\n",
    "        def get_author_names():\n",
    "            try:\n",
    "                authors = abstracts_data.get('authors', {}).get('author', [])\n",
    "                if not authors:\n",
    "                    return None\n",
    "                names = []\n",
    "                for author in authors:\n",
    "                    preferred_name = author.get('preferred-name', {})\n",
    "                    if preferred_name and 'ce:indexed-name' in preferred_name:\n",
    "                        names.append(preferred_name['ce:indexed-name'])\n",
    "                return \", \".join(names) if names else None\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "        # Helper function to safely get keywords\n",
    "        def get_keywords():\n",
    "            try:\n",
    "                keywords = abstracts_data.get('authkeywords', {}).get('author-keyword', [])\n",
    "                if not keywords:\n",
    "                    return None\n",
    "                keyword_list = [key.get('$', '') for key in keywords]\n",
    "                return \", \".join(keyword_list) if any(keyword_list) else None\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "        # Helper function to safely get subjects\n",
    "        def get_subjects():\n",
    "            try:\n",
    "                subjects = abstracts_data.get('subject-areas', {}).get('subject-area', [])\n",
    "                if not subjects:\n",
    "                    return None\n",
    "                subject_list = [subject.get('@code', '') for subject in subjects]\n",
    "                return \", \".join(subject_list) if any(subject_list) else None\n",
    "            except Exception:\n",
    "                return None\n",
    "        \n",
    "        # Create a dictionary with the data\n",
    "        paper_data = {\n",
    "            'Title': coredata.get('dc:title') or None,\n",
    "            'Publisher': coredata.get('dc:publisher') or None,\n",
    "            'Publish_date': coredata.get('prism:coverDate') or None,\n",
    "            'Authors': get_author_names(),\n",
    "            'Keywords': get_keywords(),\n",
    "            'Subjects': get_subjects()\n",
    "        }\n",
    "        \n",
    "        return paper_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        # Return empty dictionary with None values\n",
    "        return {\n",
    "            'Title': None,\n",
    "            'Publisher': None,\n",
    "            'Publish_date': None,\n",
    "            'Authors': None,\n",
    "            'Keywords': None,\n",
    "            'Subjects': None\n",
    "        }\n",
    "\n",
    "# Rest of your code remains the same\n",
    "base_path = r'C:\\Users\\USER\\Desktop\\DSDE_project\\Project\\2018\\2018'\n",
    "all_data = []\n",
    "for i in range(2792):\n",
    "    file_number = str(i).zfill(5)\n",
    "    file_path = base_path + file_number\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        paper_data = process_json_to_df(file_path)\n",
    "        all_data.append(paper_data)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processed {i} files...\")\n",
    "\n",
    "df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"2018_data.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
