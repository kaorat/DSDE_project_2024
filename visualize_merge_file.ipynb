{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "file_path_2018 = os.path.join(script_dir, '2018_trend_keyword.csv')\n",
    "file_path_2019 = os.path.join(script_dir, '2019_trend_keyword.csv')\n",
    "file_path_2020 = os.path.join(script_dir, '2020_trend_keyword.csv')\n",
    "file_path_2021 = os.path.join(script_dir, '2021_trend_keyword.csv')\n",
    "file_path_2022 = os.path.join(script_dir, '2022_trend_keyword.csv')\n",
    "file_path_2023 = os.path.join(script_dir, '2023_trend_keyword.csv')\n",
    "data_2018 = pd.read_csv(file_path_2018)\n",
    "data_2019 = pd.read_csv(file_path_2019)\n",
    "data_2020 = pd.read_csv(file_path_2020)\n",
    "data_2021 = pd.read_csv(file_path_2021)\n",
    "data_2022 = pd.read_csv(file_path_2022)\n",
    "data_2023 = pd.read_csv(file_path_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018['Year'] = 2018\n",
    "data_2019['Year'] = 2019\n",
    "data_2020['Year'] = 2020\n",
    "data_2021['Year'] = 2021\n",
    "data_2022['Year'] = 2022\n",
    "data_2023['Year'] = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>cover_date</th>\n",
       "      <th>authkey_word</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parametric study of hydrogen production via so...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Circulating fluidized bed</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parametric study of hydrogen production via so...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Computational fluid dynamics</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parametric study of hydrogen production via so...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Multiphase flow models</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parametric study of hydrogen production via so...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Riser</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parametric study of hydrogen production via so...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sorption enhanced steam methane reforming</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83183</th>\n",
       "      <td>Effects of remittances on household poverty an...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>consumption</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83184</th>\n",
       "      <td>Effects of remittances on household poverty an...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>expenditure</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83185</th>\n",
       "      <td>Effects of remittances on household poverty an...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Impact</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83186</th>\n",
       "      <td>Effects of remittances on household poverty an...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>inequality</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83187</th>\n",
       "      <td>Effects of remittances on household poverty an...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>remittances</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83188 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title  cover_date  \\\n",
       "0      Parametric study of hydrogen production via so...  2018-12-31   \n",
       "1      Parametric study of hydrogen production via so...  2018-12-31   \n",
       "2      Parametric study of hydrogen production via so...  2018-12-31   \n",
       "3      Parametric study of hydrogen production via so...  2018-12-31   \n",
       "4      Parametric study of hydrogen production via so...  2018-12-31   \n",
       "...                                                  ...         ...   \n",
       "83183  Effects of remittances on household poverty an...  2023-01-01   \n",
       "83184  Effects of remittances on household poverty an...  2023-01-01   \n",
       "83185  Effects of remittances on household poverty an...  2023-01-01   \n",
       "83186  Effects of remittances on household poverty an...  2023-01-01   \n",
       "83187  Effects of remittances on household poverty an...  2023-01-01   \n",
       "\n",
       "                                    authkey_word  Year  \n",
       "0                      Circulating fluidized bed  2018  \n",
       "1                   Computational fluid dynamics  2018  \n",
       "2                         Multiphase flow models  2018  \n",
       "3                                          Riser  2018  \n",
       "4      Sorption enhanced steam methane reforming  2018  \n",
       "...                                          ...   ...  \n",
       "83183                                consumption  2023  \n",
       "83184                                expenditure  2023  \n",
       "83185                                     Impact  2023  \n",
       "83186                                 inequality  2023  \n",
       "83187                                remittances  2023  \n",
       "\n",
       "[83188 rows x 4 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge 2018 and 2019\n",
    "\n",
    "data_merged = pd.concat([data_2018, data_2019], axis=0)\n",
    "\n",
    "# Merge merged and 2020\n",
    "\n",
    "data_merged = pd.concat([data_merged, data_2020], axis=0)\n",
    "\n",
    "# Merge merged and 2021\n",
    "\n",
    "data_merged = pd.concat([data_merged, data_2021], axis=0)\n",
    "\n",
    "# Merge merged and 2022\n",
    "\n",
    "data_merged = pd.concat([data_merged, data_2022], axis=0)\n",
    "\n",
    "# Merge merged and 2023\n",
    "\n",
    "data_merged = pd.concat([data_merged, data_2023], axis=0)\n",
    "\n",
    "data_merged['authkey_word'] = data_merged['authkey_word'].str.split(', ')\n",
    "data_merged = data_merged.explode('authkey_word').reset_index(drop=True)\n",
    "\n",
    "data_2018['authkey_word'] = data_2018['authkey_word'].str.split(', ')\n",
    "data_2018 = data_2018.explode('authkey_word').reset_index(drop=True)\n",
    "\n",
    "data_2019['authkey_word'] = data_2019['authkey_word'].str.split(', ')\n",
    "data_2019 = data_2019.explode('authkey_word').reset_index(drop=True)\n",
    "\n",
    "data_2020['authkey_word'] = data_2020['authkey_word'].str.split(', ')\n",
    "data_2020 = data_2020.explode('authkey_word').reset_index(drop=True)\n",
    "\n",
    "data_2021['authkey_word'] = data_2018['authkey_word'].str.split(', ')\n",
    "data_2021 = data_2021.explode('authkey_word').reset_index(drop=True)\n",
    "\n",
    "data_2022['authkey_word'] = data_2018['authkey_word'].str.split(', ')\n",
    "data_2022 = data_2022.explode('authkey_word').reset_index(drop=True)\n",
    "\n",
    "data_2023['authkey_word'] = data_2018['authkey_word'].str.split(', ')\n",
    "data_2023 = data_2023.explode('authkey_word').reset_index(drop=True)\n",
    "\n",
    "data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>cover_date</th>\n",
       "      <th>authkey_word</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parametric study of hydrogen production via so...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Circulating fluidized bed</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parametric study of hydrogen production via so...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Computational fluid dynamics</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parametric study of hydrogen production via so...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Multiphase flow models</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parametric study of hydrogen production via so...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Riser</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parametric study of hydrogen production via so...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sorption enhanced steam methane reforming</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23304</th>\n",
       "      <td>Data-driven techniques for modelling the gross...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>k-nearest neighbour</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23305</th>\n",
       "      <td>Data-driven techniques for modelling the gross...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Model tree</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23306</th>\n",
       "      <td>Data-driven techniques for modelling the gross...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Neural network</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23307</th>\n",
       "      <td>Data-driven techniques for modelling the gross...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Surrogate model</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23308</th>\n",
       "      <td>Data-driven techniques for modelling the gross...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Vegetation models</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106497 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title  cover_date  \\\n",
       "0      Parametric study of hydrogen production via so...  2018-12-31   \n",
       "1      Parametric study of hydrogen production via so...  2018-12-31   \n",
       "2      Parametric study of hydrogen production via so...  2018-12-31   \n",
       "3      Parametric study of hydrogen production via so...  2018-12-31   \n",
       "4      Parametric study of hydrogen production via so...  2018-12-31   \n",
       "...                                                  ...         ...   \n",
       "23304  Data-driven techniques for modelling the gross...  2018-01-01   \n",
       "23305  Data-driven techniques for modelling the gross...  2018-01-01   \n",
       "23306  Data-driven techniques for modelling the gross...  2018-01-01   \n",
       "23307  Data-driven techniques for modelling the gross...  2018-01-01   \n",
       "23308  Data-driven techniques for modelling the gross...  2018-01-01   \n",
       "\n",
       "                                    authkey_word  Year  \n",
       "0                      Circulating fluidized bed  2018  \n",
       "1                   Computational fluid dynamics  2018  \n",
       "2                         Multiphase flow models  2018  \n",
       "3                                          Riser  2018  \n",
       "4      Sorption enhanced steam methane reforming  2018  \n",
       "...                                          ...   ...  \n",
       "23304                       k-nearest neighbour   2018  \n",
       "23305                                Model tree   2018  \n",
       "23306                            Neural network   2018  \n",
       "23307                           Surrogate model   2018  \n",
       "23308                          Vegetation models  2018  \n",
       "\n",
       "[106497 rows x 4 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with Additional Data\n",
    "file_path_add = os.path.join(script_dir, 'addtionaldata_trend_keywords_fixed.csv')\n",
    "Additional_data = pd.read_csv(file_path_add)\n",
    "\n",
    "Additional_data['authkey_word'] = Additional_data['authkey_word'].str.split('|')\n",
    "Additional_data = Additional_data.explode('authkey_word').reset_index(drop=True)\n",
    "\n",
    "data_merged = pd.concat([data_merged, Additional_data], axis=0)\n",
    "\n",
    "data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 29, 80, 108, 70]\n",
      "[58, 35, 31, 28, 0, 0]\n",
      "[21, 26, 24, 32, 15, 12]\n",
      "[5, 20, 28, 69, 72, 100]\n",
      "[20, 21, 20, 17, 19, 17]\n",
      "[25, 60, 90, 185, 197, 286]\n"
     ]
    }
   ],
   "source": [
    "# Inspect Authkey_word value count for COVID-19\n",
    "COVID_list = []\n",
    "HADRON_list = []\n",
    "INFLAMM_list = []\n",
    "SAR_list = []\n",
    "HIV_list = []\n",
    "MAC_list = []\n",
    "for i in range(2018,2024):\n",
    "  key_count = data_merged[(data_merged['Year'] == i)]['authkey_word'].value_counts().reset_index().sort_values(by=['count'], ascending=False)\n",
    "  COVID_result = (key_count['count'][key_count['authkey_word'] == 'COVID-19 '].sum()) + (key_count['count'][key_count['authkey_word'] == 'COVID-19'].sum())\n",
    "  + (key_count['count'][key_count['authkey_word'] == ' COVID-19'].sum()) + (key_count['count'][key_count['authkey_word'] == ' COVID-19'].sum())\n",
    "  COVID_list.append(COVID_result)\n",
    "  HADRON_list.append(key_count['count'][key_count['authkey_word'] == 'Hadron-Hadron scattering (experiments)'].sum())\n",
    "  INFLAMM_list.append(key_count['count'][key_count['authkey_word'] == 'Inflammation'].sum())\n",
    "  climate_result = (key_count['count'][key_count['authkey_word'] == 'Climate change '].sum()) + (key_count['count'][key_count['authkey_word'] == 'Climate change'].sum())\n",
    "  + (key_count['count'][key_count['authkey_word'] == ' Climate change '].sum()) + (key_count['count'][key_count['authkey_word'] == ' Climate change'].sum())\n",
    "  SAR_list.append(climate_result)\n",
    "  HIV_list.append(key_count['count'][key_count['authkey_word'] == 'HIV'].sum())\n",
    "  MAC_list.append(key_count['count'][key_count['authkey_word'] == ' Machine learning '].sum())\n",
    "\n",
    "print(COVID_list)\n",
    "print(HADRON_list)\n",
    "print(INFLAMM_list)\n",
    "print(SAR_list)\n",
    "print(HIV_list)\n",
    "print(MAC_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_count_merged = data_merged['authkey_word'].value_counts().reset_index().sort_values(by=['count'], ascending=False)\n",
    "key_count_merged['count'][key_count_merged['authkey_word'] == 'Machine learning'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authkey_word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine learning</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Climate change</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Climate change</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>climate change</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>climate change</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hadron-Hadron scattering (experiments)</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Inflammation</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Deep learning</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SARS-CoV-2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HIV</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Remote sensing</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              authkey_word  count\n",
       "0                        Machine learning     843\n",
       "1                                 Thailand    746\n",
       "2                        machine learning     534\n",
       "3                                 COVID-19    282\n",
       "4                          Climate change     280\n",
       "5                          Climate change     239\n",
       "6                        Machine Learning     179\n",
       "7                          climate change     171\n",
       "8                          climate change     156\n",
       "9   Hadron-Hadron scattering (experiments)    152\n",
       "10                            Inflammation    130\n",
       "11                          Deep learning     115\n",
       "12                              SARS-CoV-2    115\n",
       "13                                     HIV    114\n",
       "14                         Remote sensing     111"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COVID-19 ( COVID-19) ( SARS-CoV-2)\n",
    "key_count_merged = data_merged['authkey_word'].value_counts().reset_index().sort_values(by=['count'], ascending=False)\n",
    "key_count_merged.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a DataFrame\n",
    "data = [\n",
    "  ['Machine Learning', 2018, MAC_list[0]],\n",
    "  ['Machine Learning', 2019, MAC_list[1]],\n",
    "  ['Machine Learning', 2020, MAC_list[2]],\n",
    "  ['Machine Learning', 2021, MAC_list[3]],\n",
    "  ['Machine Learning', 2022, MAC_list[4]],\n",
    "  ['Machine Learning', 2023, MAC_list[5]],\n",
    "  ['Climate Change', 2018, SAR_list[0]],\n",
    "  ['Climate Change', 2019, SAR_list[1]],\n",
    "  ['Climate Change', 2020, SAR_list[2]],\n",
    "  ['Climate Change', 2021, SAR_list[3]],\n",
    "  ['Climate Change', 2022, SAR_list[4]],\n",
    "  ['Climate Change', 2023, SAR_list[5]],\n",
    "  ['COVID-19', 2018, COVID_list[0]],\n",
    "  ['COVID-19', 2019, COVID_list[1]],\n",
    "  ['COVID-19', 2020, COVID_list[2]],\n",
    "  ['COVID-19', 2021, COVID_list[3]],\n",
    "  ['COVID-19', 2022, COVID_list[4]],\n",
    "  ['COVID-19', 2023, COVID_list[5]],\n",
    "  ['Hadron-Hadron scattering (experiments)', 2018, HADRON_list[0]],\n",
    "  ['Hadron-Hadron scattering (experiments)', 2019, HADRON_list[1]],\n",
    "  ['Hadron-Hadron scattering (experiments)', 2020, HADRON_list[2]],\n",
    "  ['Hadron-Hadron scattering (experiments)', 2021, HADRON_list[3]],\n",
    "  ['Hadron-Hadron scattering (experiments)', 2022, HADRON_list[4]],\n",
    "  ['Hadron-Hadron scattering (experiments)', 2023, HADRON_list[5]],\n",
    "  ['Inflammation', 2018, INFLAMM_list[0]],\n",
    "  ['Inflammation', 2019, INFLAMM_list[1]],\n",
    "  ['Inflammation', 2020, INFLAMM_list[2]],\n",
    "  ['Inflammation', 2021, INFLAMM_list[3]],\n",
    "  ['Inflammation', 2022, INFLAMM_list[4]],\n",
    "  ['Inflammation', 2023, INFLAMM_list[5]],\n",
    "  ['HIV', 2018, HIV_list[0]],\n",
    "  ['HIV', 2019, HIV_list[1]],\n",
    "  ['HIV', 2020, HIV_list[2]],\n",
    "  ['HIV', 2021, HIV_list[3]],\n",
    "  ['HIV', 2022, HIV_list[4]],\n",
    "  ['HIV', 2023, HIV_list[5]],\n",
    "]\n",
    "\n",
    "export_data = pd.DataFrame(\n",
    "  data,\n",
    "  columns=['Keyword','Year','Count']\n",
    ")\n",
    "\n",
    "# Export merged data to csv\n",
    "export_data.to_csv('merged_trend_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
